{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IGM selffocus nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qR2B9LwQP5Sj",
        "gnq4aUKHSan_"
      ],
      "authorship_tag": "ABX9TyNAk/zHJ4V0zcsCj5grAS1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unerriar/igm-selffocus-nn/blob/main/IGM_selffocus_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICrMlVoJPqre"
      },
      "source": [
        "#Imports and datasets uploadig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ2BS7qwFDw6"
      },
      "source": [
        "import os, os.path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "from itertools import chain\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEPa7APNGG6f",
        "outputId": "ee4baa0f-bc18-469c-dad2-abc21e9a13c6"
      },
      "source": [
        "! git clone https://github.com/unerriar/igm-selffocus-nn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'igm-selffocus-nn'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 36 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri61yzUCOnki"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/igm-selffocus-nn'"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPVEAkhXGT6k"
      },
      "source": [
        "! kaggle datasets download -d unerriar/igmselffocus\n",
        "! unzip 'igmselffocus.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6W1QrtsGwQ"
      },
      "source": [
        "! unzip 'igmselffocus.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR2B9LwQP5Sj"
      },
      "source": [
        "#Helper classes\n",
        "\n",
        "FieldMediumDataset: *stores data and returns it in batches.*\n",
        "\n",
        "Workfow: *implements main train-test routine and allows to easylly upload best saved model weights*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq4GBlBUP6I_"
      },
      "source": [
        "class FieldMediumDataset(Dataset):\n",
        "    def __init__(self, dir, field_res, elems):\n",
        "        super(FieldMediumDataset, self).__init__()\n",
        "\n",
        "        self.field_res = field_res\n",
        "        self.elements = elems\n",
        "        self.dir = dir\n",
        "        \n",
        "        self.in_fields  = np.stack([self._extract_field('in_'+str(i)+'.bin') for i in range(*elems)])\n",
        "        self.out_fields = np.stack([self._extract_field('out_'+str(i)+'.bin') for i in range(*elems)])\n",
        "        self.medium = np.stack([self._extract_medium('medium_'+str(i)+'.bin') for i in range(*elems)])   \n",
        "\n",
        "    def _extract_field(self, f):\n",
        "        file_ = open(self.dir+'/'+f, 'rb')\n",
        "        data  = np.fromfile(file_, dtype=np.complex64)\n",
        "        file_.close()\n",
        "        data_p = data[::2].reshape((self.field_res, self.field_res))\n",
        "        data_m = data[1::2].reshape((self.field_res, self.field_res))\n",
        "        return np.stack((np.real(data_p), np.imag(data_p), np.real(data_m), np.imag(data_m)))\n",
        "\n",
        "    def _extract_medium(self, f):\n",
        "        file_ = open(self.dir+'/'+f, 'rb')\n",
        "        data  = np.fromfile(file_, dtype=np.float64).astype('float32')\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.in_fields[i], self.out_fields[i], self.medium[i])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.elements[1] - self.elements[0]\n",
        "\n",
        "class Workflow():\n",
        "    def __init__(self, model, model_name='Untitled', save_dir=None,\n",
        "                 loss_fn=nn.MSELoss, optimizer=torch.optim.SGD, optim_params={'lr':.1}):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print('using ' + self.device)\n",
        "        \n",
        "        self.model = model.to(self.device)\n",
        "        self.loss_fn = loss_fn()\n",
        "        self.save_dir = save_dir\n",
        "        self.optimizer = optimizer(model.parameters(), **optim_params)\n",
        "        self.model_name = model_name\n",
        "        self.optim_params = optim_params\n",
        "        \n",
        "        self.best_loss = 9999 #pseudoinfinity\n",
        "    \n",
        "    def train(self, n_epoch, trainloader, testloader,\n",
        "              history_tracing=50, refresh_time=5, in_fields=True):\n",
        "        \"\"\"\n",
        "        Full train-test routine\n",
        "        \n",
        "        Parameters\n",
        "\n",
        "        n_epochs : int\n",
        "            number of epochs to learn\n",
        "        trainloader : torch.utils.data.DataLoader\n",
        "            train dataset dataloader\n",
        "        testloader : torch.utils.data.DataLoader\n",
        "            test dataset dataloader\n",
        "        history_tracing : int\n",
        "            number of past epochs to track detailed data about.\n",
        "            Does not affect model behaviour\n",
        "        refresh_time : int\n",
        "            number of epochs between plots and info being refreshed.\n",
        "            Does not affect the model behaviour\n",
        "        in_fields : 'zeros' | True | False\n",
        "            True:    the model will get both input and output fields (requires 8 in_channels)\n",
        "            False:   the model will get only output fields (requires 4 in_channels)\n",
        "            'zeros': the model will get zero tensor instead of input fields (requires 8 in_channels)\n",
        "        \"\"\"\n",
        "        train_loss_history = np.empty(0)\n",
        "        test_loss_history  = np.empty(0)\n",
        "        \n",
        "        for e in range(n_epoch):\n",
        "            train_loss = self._train(trainloader, in_fields=in_fields)\n",
        "            test_loss  = self._test(testloader, in_fields=in_fields)\n",
        "\n",
        "            train_loss_history = np.append(train_loss_history, train_loss)\n",
        "            test_loss_history  = np.append(test_loss_history,  test_loss)\n",
        "            \n",
        "            #loss dynamics monitoring\n",
        "            hist_len = min(e+1, history_tracing)\n",
        "            test_loss_mean  = np.mean(test_loss_history[-hist_len:])\n",
        "            test_loss_std   = np.std(test_loss_history[-hist_len:])\n",
        "            test_loss_delta = test_loss - test_loss_history[-hist_len]\n",
        "\n",
        "            #saving best model\n",
        "            if test_loss < self.best_loss:\n",
        "                self.best_loss = test_loss\n",
        "                torch.save(model.state_dict(), self.save_dir+'/'+self.model_name+'.pth')\n",
        "\n",
        "            #learning visualization\n",
        "            if (e+1) % refresh_time == 0:\n",
        "                output.clear()\n",
        "                print(f'Epoch {e+1}/{n_epoch}:\\nTrain loss: {train_loss:.4}, test loss: {test_loss:.4}')\n",
        "                print(f'Test loss during last {hist_len} epochs:')\n",
        "                print(f'Mean: {test_loss_mean:.4}, std dev: {test_loss_std:.4}, delta: {test_loss_delta:.6}:')\n",
        "                print(f'Best test loss: {self.best_loss:.4}')\n",
        "\n",
        "                fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,7))\n",
        "                ax1.plot(range(len(train_loss_history)), train_loss_history, label='train')\n",
        "                ax1.plot(range(len(test_loss_history )), test_loss_history,  label='test')\n",
        "                ax1.set_xlabel('epoch')\n",
        "                ax1.set_ylabel('loss')\n",
        "                ax1.legend()\n",
        "                \n",
        "                ax2.plot(range(len(train_loss_history)), train_loss_history, label='train')\n",
        "                ax2.plot(range(len(test_loss_history )), test_loss_history,  label='test')\n",
        "                ax2.set_yscale('log')\n",
        "                ax2.set_xlabel('epoch')\n",
        "                ax2.set_ylabel('loss (log scale)')\n",
        "                ax2.legend()\n",
        "\n",
        "                plt.show()\n",
        "    \n",
        "    def validate(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch validation\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "\n",
        "        print(f'Validation loss: {ep_loss / batch_num}')\n",
        "            \n",
        "        return ep_loss / batch_num\n",
        "\n",
        "    def load_best(self):\n",
        "        \"\"\"\n",
        "        Upload best saved model.\n",
        "        \"\"\"\n",
        "        model.load_state_dict(torch.load(self.save_dir+'/'+self.model_name+'.pth'))\n",
        "\n",
        "    def _train(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch train phase\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.train()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "\n",
        "            #backpropagation\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return ep_loss / batch_num\n",
        "\n",
        "    def _test(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch test phase\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "    \n",
        "        return ep_loss / batch_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnq4aUKHSan_"
      },
      "source": [
        "#Network\n",
        "\n",
        "General artificial neural network architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in1rj--OSbdl"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_channels=4, hidden_neurons=(16, 32, 16, 64, 32), cact=nn.Tanh, lact=nn.ReLU):\n",
        "        super(Network, self).__init__()\n",
        "                \n",
        "        self.convolutions = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_neurons[0], 4, 4), #64\n",
        "            cact(),\n",
        "            nn.Conv2d(hidden_neurons[0], hidden_neurons[1], 4, 4), #16\n",
        "            cact(),\n",
        "            nn.Conv2d(hidden_neurons[1], hidden_neurons[2], 4, 4), #4\n",
        "            cact(),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear  = nn.Sequential(\n",
        "            nn.Linear(hidden_neurons[2] * 4**2, hidden_neurons[3]),\n",
        "            lact(),\n",
        "            nn.Linear(hidden_neurons[3], hidden_neurons[4]),\n",
        "            lact(),\n",
        "            nn.Linear(hidden_neurons[4], 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutions(x)\n",
        "        x = self.flatten(x)\n",
        "        return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0BlMZQeSgO4"
      },
      "source": [
        "#Dataloader construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSHDrtHUTsVX"
      },
      "source": [
        "field_resolution = 256 #spatial resolution of the input and output fields\n",
        "batch_size = 64\n",
        "total_n = 1024 #total number of dataset samples\n",
        "test_n  = 256  #number of samples in the test subset\n",
        "valid_n = 128  #number of samples in the validation subset\n",
        "train_n = total_n - test_n - valid_n #number of samples in the train subset\n",
        "dir = 'SingularDataset/SingularDataset'\n",
        "\n",
        "valid_dataset = FieldMediumDataset(dir, field_resolution,  [0, valid_n])\n",
        "test_dataset  = FieldMediumDataset(dir, field_resolution,  [valid_n, valid_n+test_n])\n",
        "train_dataset = FieldMediumDataset(dir, field_resolution,  [valid_n+test_n, total_n])\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=True)\n",
        "test_dataloader  = DataLoader(test_dataset,  batch_size, shuffle=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg52pfUnUJfi"
      },
      "source": [
        "#Training\n",
        "\n",
        "This section is optional if you want to experiment with training parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuQ9aT9SUIaB"
      },
      "source": [
        "#making model deterministic\n",
        "torch.manual_seed(1)\n",
        "\n",
        "in_fields_mode = False #True  to give the input field profiles to the model\n",
        "                       #False to use model without input field profiles\n",
        "                       #'zeros' to use model with field profiles but set their channels to zero.\n",
        "in_channels = 8 if in_fields_mode else 4\n",
        "\n",
        "model = Network(\n",
        "    in_channels = in_channels, \n",
        "    hidden_neurons = (16, 32, 16, 64, 32),\n",
        "    cact = nn.Tanh,\n",
        "    lact = nn.ReLU\n",
        ")\n",
        "optim_params = {'lr':.0003}\n",
        "\n",
        "workflow = Workflow(\n",
        "    model, 'Singular',\n",
        "    save_dir = '/content',\n",
        "    optimizer = torch.optim.Adam,\n",
        "    optim_params = optim_params,\n",
        ")\n",
        "\n",
        "workflow.train(\n",
        "    n_epoch = 500, \n",
        "    trainloader = train_dataloader,\n",
        "    testloader = test_dataloader,\n",
        "    history_tracing = 20,\n",
        "    refresh_time = 20,\n",
        "    in_fields = in_fields_mode\n",
        ")\n",
        "\n",
        "workflow.load_best()\n",
        "workflow.validate(\n",
        "    valid_dataloader,\n",
        "    in_fields = in_fields_mode\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeHf4VnjkrOp"
      },
      "source": [
        "#Uploading pretrained networks\n",
        "\n",
        "With this section you can upload the model, pretrained by the authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRISMYzWlaHL"
      },
      "source": [
        "#making model deterministic\n",
        "torch.manual_seed(1)\n",
        "\n",
        "in_fields_mode = False #True  to give the input field profiles to the model\n",
        "                       #False to use model without input field profiles\n",
        "                       #'zeros' to use model with field profiles but set their channels to zero.\n",
        "in_channels = 8 if in_fields_mode else 4\n",
        "\n",
        "model = Network(\n",
        "    in_channels = in_channels, \n",
        "    hidden_neurons = (16, 32, 16, 64, 32),\n",
        "    cact = nn.Tanh,\n",
        "    lact = nn.ReLU\n",
        ")\n",
        "optim_params = {'lr':.0002}\n",
        "\n",
        "workflow = Workflow(\n",
        "    model, 'Singular',\n",
        "    save_dir = '/content/igm-selffocus-nn',\n",
        "    optimizer = torch.optim.Adam,\n",
        "    optim_params = optim_params,\n",
        ")\n",
        "\n",
        "workflow.load_best()\n",
        "workflow.validate(\n",
        "    valid_dataloader,\n",
        "    in_fields = in_fields_mode\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
