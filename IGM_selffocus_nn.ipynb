{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unerriar/igm-selffocus-nn/blob/main/IGM_selffocus_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICrMlVoJPqre"
      },
      "source": [
        "#Imports\n",
        "\n",
        "Run this firstly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ2BS7qwFDw6"
      },
      "outputs": [],
      "source": [
        "import os, os.path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "from itertools import chain\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEPa7APNGG6f",
        "outputId": "ad852042-c4b8-4b8a-ebe6-967514fc327d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'igm-selffocus-nn'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 139 (delta 8), reused 0 (delta 0), pack-reused 110\u001b[K\n",
            "Receiving objects: 100% (139/139), 1.93 MiB | 8.66 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/unerriar/igm-selffocus-nn.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu5yDpvnxfZe"
      },
      "source": [
        "# Kaggle upload\n",
        "\n",
        "Run this section to automatically upload four mode datasets of the article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri61yzUCOnki"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/igm-selffocus-nn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPVEAkhXGT6k"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d 'unerriar/igmselffocus'\n",
        "! unzip 'igmselffocus.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR2B9LwQP5Sj"
      },
      "source": [
        "#Helper classes\n",
        "\n",
        "FieldMediumDataset: *stores data and returns it in batches.*\n",
        "\n",
        "Workfow: *implements main train-validation routine and allows to easylly upload best saved model weights*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq4GBlBUP6I_"
      },
      "outputs": [],
      "source": [
        "class FieldMediumDataset(Dataset):\n",
        "    def __init__(self, dir, field_res, elems):\n",
        "        super(FieldMediumDataset, self).__init__()\n",
        "\n",
        "        self.field_res = field_res\n",
        "        self.elements = elems\n",
        "        self.dir = dir\n",
        "        \n",
        "        self.in_fields  = np.stack([self._extract_field('in_'+str(i)+'.bin') for i in range(*elems)])\n",
        "        self.out_fields = np.stack([self._extract_field('out_'+str(i)+'.bin') for i in range(*elems)])\n",
        "        self.medium = np.stack([self._extract_medium('medium_'+str(i)+'.bin') for i in range(*elems)])   \n",
        "\n",
        "    def _extract_field(self, f):\n",
        "        file_ = open(self.dir+'/'+f, 'rb')\n",
        "        data  = np.fromfile(file_, dtype=np.complex64)\n",
        "        file_.close()\n",
        "        data_p = data[::2].reshape((self.field_res, self.field_res))\n",
        "        data_m = data[1::2].reshape((self.field_res, self.field_res))\n",
        "        return np.stack((np.real(data_p), np.imag(data_p), np.real(data_m), np.imag(data_m)))\n",
        "\n",
        "    def _extract_medium(self, f):\n",
        "        file_ = open(self.dir+'/'+f, 'rb')\n",
        "        data  = np.fromfile(file_, dtype=np.float64).astype('float32')\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.in_fields[i], self.out_fields[i], self.medium[i])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.elements[1] - self.elements[0]\n",
        "\n",
        "class Workflow():\n",
        "    def __init__(self, model, model_name='Untitled', save_dir=None,\n",
        "                 loss_fn=nn.MSELoss, optimizer=torch.optim.SGD, optim_params={'lr':.1}):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print('using ' + self.device)\n",
        "        \n",
        "        self.model = model.to(self.device)\n",
        "        self.loss_fn = loss_fn()\n",
        "        self.save_dir = save_dir\n",
        "        self.optimizer = optimizer(model.parameters(), **optim_params)\n",
        "        self.model_name = model_name\n",
        "        self.optim_params = optim_params\n",
        "        \n",
        "        self.best_loss = 9999 #pseudoinfinity\n",
        "    \n",
        "    def train(self, n_epoch, trainloader, validloader,\n",
        "              history_tracing=50, refresh_time=5, in_fields=True):\n",
        "        \"\"\"\n",
        "        Full train-validation routine\n",
        "        \n",
        "        Parameters\n",
        "\n",
        "        n_epochs : int\n",
        "            number of epochs to learn\n",
        "        trainloader : torch.utils.data.DataLoader\n",
        "            train dataset dataloader\n",
        "        validloader : torch.utils.data.DataLoader\n",
        "            validation dataset dataloader\n",
        "        history_tracing : int\n",
        "            number of past epochs to track detailed data about.\n",
        "            Does not affect model behaviour\n",
        "        refresh_time : int\n",
        "            number of epochs between plots and info being refreshed.\n",
        "            Does not affect the model behaviour\n",
        "        in_fields : 'zeros' | True | False\n",
        "            True:    the model will get both input and output fields (requires 8 in_channels)\n",
        "            False:   the model will get only output fields (requires 4 in_channels)\n",
        "            'zeros': the model will get zero tensor instead of input fields (requires 8 in_channels)\n",
        "        \"\"\"\n",
        "        train_loss_history = np.empty(0)\n",
        "        valid_loss_history  = np.empty(0)\n",
        "        \n",
        "        for e in range(n_epoch):\n",
        "            train_loss = self._train(trainloader, in_fields=in_fields)\n",
        "            valid_loss = self._valid(validloader, in_fields=in_fields)\n",
        "\n",
        "            train_loss_history = np.append(train_loss_history, train_loss)\n",
        "            valid_loss_history = np.append(valid_loss_history, valid_loss)\n",
        "            \n",
        "            #loss dynamics monitoring\n",
        "            hist_len = min(e+1, history_tracing)\n",
        "            valid_loss_mean  = np.mean(valid_loss_history[-hist_len:])\n",
        "            valid_loss_std   = np.std(valid_loss_history[-hist_len:])\n",
        "            valid_loss_delta = valid_loss - valid_loss_history[-hist_len]\n",
        "\n",
        "            #saving best model\n",
        "            if valid_loss < self.best_loss:\n",
        "                self.best_loss = valid_loss\n",
        "                torch.save(self.model.state_dict(), self.save_dir+'/'+self.model_name+'.pth')\n",
        "\n",
        "            #learning visualization\n",
        "            if (e+1) % refresh_time == 0:\n",
        "                output.clear()\n",
        "                print(f'Epoch {e+1}/{n_epoch}:\\nTrain loss: {train_loss:.4}, validation loss: {valid_loss:.4}')\n",
        "                print(f'Validation loss during last {hist_len} epochs:')\n",
        "                print(f'Mean: {valid_loss_mean:.4}, std dev: {valid_loss_std:.4}, delta: {valid_loss_delta:.6}:')\n",
        "                print(f'Best validation loss: {self.best_loss:.4}')\n",
        "\n",
        "                fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,7))\n",
        "                ax1.plot(range(len(train_loss_history)), train_loss_history, label='train')\n",
        "                ax1.plot(range(len(valid_loss_history )), valid_loss_history,  label='valid')\n",
        "                ax1.set_xlabel('epoch')\n",
        "                ax1.set_ylabel('loss')\n",
        "                ax1.legend()\n",
        "                \n",
        "                ax2.plot(range(len(train_loss_history)), train_loss_history, label='train')\n",
        "                ax2.plot(range(len(valid_loss_history )), valid_loss_history,  label='valid')\n",
        "                ax2.set_yscale('log')\n",
        "                ax2.set_xlabel('epoch')\n",
        "                ax2.set_ylabel('loss (log scale)')\n",
        "                ax2.legend()\n",
        "\n",
        "                plt.show()\n",
        "    \n",
        "    def test(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch test\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = self.model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = self.model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = self.model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "\n",
        "        print(f'Test loss: {ep_loss / batch_num}')\n",
        "            \n",
        "        return ep_loss / batch_num\n",
        "\n",
        "    def load_best(self):\n",
        "        \"\"\"\n",
        "        Upload best saved model.\n",
        "        \"\"\"\n",
        "        self.model.load_state_dict(torch.load(self.save_dir+'/'+self.model_name+'.pth'))\n",
        "\n",
        "    def _train(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch train phase\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.train()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = self.model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = self.model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = self.model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "\n",
        "            #backpropagation\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return ep_loss / batch_num\n",
        "\n",
        "    def _valid(self, dataloader, in_fields=True):\n",
        "        \"\"\"\n",
        "        Single epoch valid phase\n",
        "        \"\"\"\n",
        "        batch_num = len(dataloader)\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        ep_loss = 0\n",
        "        for batch, (in_field, out_field, medium) in enumerate(dataloader):\n",
        "            in_field, out_field, medium = in_field.to(self.device), out_field.to(self.device), medium.to(self.device)\n",
        "\n",
        "            #error computation\n",
        "            if in_fields == 'zeros':\n",
        "                predict = self.model(torch.cat((0*in_field, out_field), axis=1))\n",
        "            elif in_fields:\n",
        "                predict = self.model(torch.cat((in_field, out_field), axis=1))\n",
        "            else:\n",
        "                predict = self.model(out_field)\n",
        "            loss = self.loss_fn(predict, medium)\n",
        "            ep_loss += loss.item()\n",
        "    \n",
        "        return ep_loss / batch_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnq4aUKHSan_"
      },
      "source": [
        "#Network\n",
        "\n",
        "General artificial neural network architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in1rj--OSbdl"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, in_channels=4, hidden_neurons=(4, 8, 16, 40, 60), cact=nn.Tanh, lact=nn.ReLU):\n",
        "        super(Network, self).__init__()\n",
        "                \n",
        "        self.convolutions = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_neurons[0], 4, 4), #64\n",
        "            cact(),\n",
        "            nn.Conv2d(hidden_neurons[0], hidden_neurons[1], 4, 4), #16\n",
        "            cact(),\n",
        "            nn.Conv2d(hidden_neurons[1], hidden_neurons[2], 4, 4), #4\n",
        "            cact(),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear  = nn.Sequential(\n",
        "            nn.Linear(hidden_neurons[2] * 4**2, hidden_neurons[3]),\n",
        "            lact(),\n",
        "            nn.Linear(hidden_neurons[3], hidden_neurons[4]),\n",
        "            lact(),\n",
        "            nn.Linear(hidden_neurons[4], 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutions(x)\n",
        "        x = self.flatten(x)\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0BlMZQeSgO4"
      },
      "source": [
        "#Dataloader construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSHDrtHUTsVX"
      },
      "outputs": [],
      "source": [
        "field_resolution = 256 #spatial resolution of the input and output fields\n",
        "batch_size = 256\n",
        "total_n = 2048 #total number of dataset samples\n",
        "valid_n = 512  #number of samples in the validation subset\n",
        "test_n  = 256  #number of samples in the test subset\n",
        "train_n = total_n - valid_n - test_n #number of samples in the train subset\n",
        "field_mode = 'Gaussian' # Gaussian | Supergaussian | Laguerre | Poincare\n",
        "dir = field_mode + 'Dataset'\n",
        "\n",
        "test_dataset  = FieldMediumDataset(dir, field_resolution, [0, test_n])\n",
        "valid_dataset = FieldMediumDataset(dir, field_resolution, [test_n, test_n+valid_n])\n",
        "train_dataset = FieldMediumDataset(dir, field_resolution, [test_n+valid_n, total_n])\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
        "valid_dataloader  = DataLoader(valid_dataset,  batch_size, shuffle=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg52pfUnUJfi"
      },
      "source": [
        "#Training\n",
        "\n",
        "This section is optional if you want to experiment with training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq0xdBNG9MZg"
      },
      "outputs": [],
      "source": [
        "#making model deterministic\n",
        "torch.manual_seed(1)\n",
        "\n",
        "in_fields_mode = True  #True  to give the input field profiles to the model\n",
        "                       #False to use model without input field profiles\n",
        "                       #'zeros' to use model with field profiles but set their channels to zero.\n",
        "in_channels = 8 if in_fields_mode else 4\n",
        "\n",
        "model = Network(\n",
        "    in_channels = in_channels, \n",
        "    hidden_neurons = (4, 8, 16, 60, 40),\n",
        "    cact = nn.Tanh,\n",
        "    lact = nn.ReLU\n",
        ")\n",
        "optim_params = {'lr':0.0005}\n",
        "\n",
        "workflow = Workflow(\n",
        "    model, field_mode,\n",
        "    save_dir = '/content/igm-selffocus-nn',\n",
        "    optimizer = torch.optim.Adam,\n",
        "    optim_params = optim_params,\n",
        ")\n",
        "\n",
        "workflow.train(\n",
        "    n_epoch = 2500, \n",
        "    trainloader = train_dataloader,\n",
        "    validloader  = valid_dataloader,\n",
        "    history_tracing = 20,\n",
        "    refresh_time    = 20,\n",
        "    in_fields = in_fields_mode\n",
        ")\n",
        "workflow.test(\n",
        "    test_dataloader,\n",
        "    in_fields = in_fields_mode\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeHf4VnjkrOp"
      },
      "source": [
        "#Uploading pretrained networks\n",
        "\n",
        "With this section you can upload the model, pretrained by the authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRISMYzWlaHL"
      },
      "outputs": [],
      "source": [
        "#making model deterministic\n",
        "torch.manual_seed(1)\n",
        "\n",
        "in_fields_mode = False #True  to give the input field profiles to the model\n",
        "                       #False to use model without input field profiles\n",
        "                       #'zeros' to use model with field profiles but set their channels to zero.\n",
        "in_channels = 8 if in_fields_mode else 4\n",
        "\n",
        "model = Network(\n",
        "    in_channels = in_channels, \n",
        "    hidden_neurons = (4, 8, 16, 40, 60),\n",
        "    cact = nn.Tanh,\n",
        "    lact = nn.ReLU\n",
        ")\n",
        "optim_params = {'lr':.0005}\n",
        "\n",
        "workflow = Workflow(\n",
        "    model, field_mode,\n",
        "    save_dir = '/content/igm-selffocus-nn',\n",
        "    optimizer = torch.optim.Adam,\n",
        "    optim_params = optim_params,\n",
        ")\n",
        "\n",
        "workflow.load_best()\n",
        "workflow.test(\n",
        "    test_dataloader,\n",
        "    in_fields = in_fields_mode\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONpi01LMQU75"
      },
      "source": [
        "#Error statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcO4j941bRXL"
      },
      "outputs": [],
      "source": [
        "for dataloader, datatype in [(train_dataloader, '_train'),\n",
        "                             (valid_dataloader, '_valid'),\n",
        "                             (test_dataloader,  '_test')]:\n",
        "\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        if idx == 0:\n",
        "            pred  = workflow.model(torch.cat((data[0], data[1]), axis=1).to('cuda')).cpu().detach().numpy()\n",
        "            truth = data[2].detach().numpy()\n",
        "        else:\n",
        "            pred  = np.concatenate((pred, workflow.model(torch.cat((data[0], data[1]), axis=1).to('cuda')).cpu().detach().numpy()))\n",
        "            truth = np.concatenate((truth, data[2].detach().numpy()))\n",
        "\n",
        "    pred_file = open(field_mode+datatype+'_pred.bin', 'wb')\n",
        "    truth_file = open(field_mode+datatype+'_truth.bin', 'wb')\n",
        "    pred.tofile(pred_file)  \n",
        "    truth.tofile(truth_file)    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ICrMlVoJPqre",
        "fu5yDpvnxfZe",
        "K3Z0JasNxG6f",
        "qR2B9LwQP5Sj",
        "gnq4aUKHSan_",
        "MeHf4VnjkrOp",
        "ONpi01LMQU75"
      ],
      "name": "IGM selffocus nn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}